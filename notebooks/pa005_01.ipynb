{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. BUSINESS JOB DESCRIPTION\n",
    "\n",
    "*   Our client is an e-commerce company (_All in one Place_), a multibrand outlet. It profits comes from reseling large quantities of various products by offering low tag prices.\n",
    "\n",
    "*   After collecting data from their clients database during the period of 1 year, the company's marketing team is analyzing wheter it would be profitable or not to separate it into distinct groups, in order to distinguish those who represent a larger ammount of the company's earnings.\n",
    "\n",
    "*   The intended group of interest obtained from this clustering analysis will then be called 'Insiders', and will be targeted as eligible clients to win special fidelity programs opportunities.\n",
    "\n",
    "## ii. THE CHALLENGE\n",
    "\n",
    "*   I was hired as a Data Scientist consultant, in order to build a model capable of performing such clustering with great accuracy.\n",
    "\n",
    "*   With the solution, the marketing team can acordingly plan how to target groups of clients in order to optimize profits.\n",
    "\n",
    "*   In order to understand client's behaviour, we have a database containing information about sales transactions, specifying the products that were bought, their description, quantity, unit price as well as general information about client's physical location (Customer ID, country).\n",
    "\n",
    "## iii. BUSINESS QUESTIONS\n",
    "\n",
    "*   It is expected a report as the result of the clsutering analysis, which answers the following questions:\n",
    "\n",
    "    1.  Which clients are eligible  to take part on the 'Insiders' group ?\n",
    "    \n",
    "    2.  How many clients will be selected?\n",
    "\n",
    "    3.  What are the main features that impacts more the clustering analysis from said clients?\n",
    "\n",
    "    4.  What is the 'Insiders' group percentage upon the company's total earnings?\n",
    "    \n",
    "    5.  What is the expected profit from the 'Insiders' group for the next months?\n",
    "\n",
    "    6.  What are the main conditions that make one eligible for being on 'Insiders'?\n",
    "\n",
    "    7.  What are the conditions for one to be excluded from 'Insiders'?\n",
    "\n",
    "    8.  What guarantees that 'Insiders' group grants more profits to the company compared to the rest of the database?\n",
    "\n",
    "    9.  Which actions the marketing team can partake to increase profits?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 IMPORTS, FUNCTIONS AND DATABASE LOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas       as pd\n",
    "import numpy        as np\n",
    "import seaborn      as sns\n",
    "import scikitplot   as skplt\n",
    "import xgboost      as xgb\n",
    "import lightgbm     as lgbm\n",
    "import inflection\n",
    "import optuna\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from matplotlib     import pyplot as plt\n",
    "from collections    import Counter\n",
    "\n",
    "from sklearn.preprocessing      import MinMaxScaler, StandardScaler\n",
    "from sklearn.dummy              import DummyClassifier\n",
    "from sklearn.ensemble           import RandomForestRegressor, ExtraTreesClassifier\n",
    "from sklearn.linear_model       import LogisticRegression\n",
    "from sklearn.neighbors          import KNeighborsClassifier\n",
    "from sklearn.model_selection    import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics            import log_loss\n",
    "\n",
    "from imblearn.ensemble          import BalancedRandomForestClassifier\n",
    "from imblearn.pipeline          import Pipeline\n",
    "from imblearn.combine           import SMOTEENN\n",
    "from imblearn.under_sampling    import EditedNearestNeighbours\n",
    "\n",
    "from optuna.integration     import XGBoostPruningCallback\n",
    "from optuna.visualization   import plot_param_importances\n",
    "from optuna.pruners         import MedianPruner\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display      import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings ('ignore')\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "\n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "\n",
    "    display( HTML( '<style>.container { width:90% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "\n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Database load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Generall Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('')   \n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of Rows: {df1.shape[0]}')\n",
    "print(f'Number of Columns: {df1.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Data Typification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** DESCRIÇÃO QUALITATIVA DE CADA COLUNA ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_old = []\n",
    "\n",
    "snakecase = lambda x: inflection.underscore(x)\n",
    "cols_new = list(map(snakecase, cols_old))\n",
    "\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *** CHCAGEM DE CONFORMIDADE DO TIPO DE DADO EM CADA COLUNA ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Missing Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** VERIFICAR ESTRATÉGIAS ADEQUADAS DE PREENCHIMENTO DE DADOS FALTANTES ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Numerical Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Selection\n",
    "df1_num = df1.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "#Central Tendency\n",
    "ct1 = pd.DataFrame(df1_num.apply(np.mean)).T\n",
    "ct2 = pd.DataFrame(df1_num.apply(np.median)).T\n",
    "\n",
    "#Dispersion\n",
    "d1 = pd.DataFrame(df1_num.apply(min)).T\n",
    "d2 = pd.DataFrame(df1_num.apply(max)).T\n",
    "d3 = pd.DataFrame(df1_num.apply(lambda x: x.max() - x.min())).T\n",
    "d4 = pd.DataFrame(df1_num.apply(np.std)).T\n",
    "d5 = pd.DataFrame(df1_num.apply(lambda x: x.skew())).T\n",
    "d6 = pd.DataFrame(df1_num.apply(lambda x: x.kurtosis())).T\n",
    "\n",
    "df_descript = pd.concat([d1, d2, d3, ct1, ct2, d4, d5, d6]).T\n",
    "df_descript.columns = ['min','max', 'range', 'average', 'median', 'std', 'skew', 'kurtosis']\n",
    "df_descript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** ANOTAR OBSERVAÇÕES SOBRE AS DISTRIBUIÇÕES OBSERVADAS E POSSÍVEIS INSIGHTS ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Categorical Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** ANOTAR OBSERVAÇÕES SOBRE AS DISTRIBUIÇÕES OBSERVADAS E POSSÍVEIS INSIGHTS ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Hypothesis Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Hypothesis Mindmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Created Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 EDA and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Univariative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_num = df2.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "df2_num.hist(bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Verificar comportamento das distribuições/outliers ***\n",
    "*** Verificar Comportamento das variáveis categóricas ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Bivariative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Validação das Hipóteses/ Feature Engineering/ Mapa de Calor ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 RESULTS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 MODEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackday_08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
